{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanha2301/AIR-absa-rt/blob/main/lexicon_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAGrsSTI3woA"
      },
      "source": [
        "# Lexicon-based Sentiment (VI) — VietSentiWordNet + NegDict + SacThaiDict\n",
        "\n",
        "Notebook **cơ bản** (không argparse / không CLI).  \n",
        "Mục tiêu: đọc 3 file `.txt` bạn đưa và tính sentiment theo luật:\n",
        "\n",
        "- **VietSentiWordnet_Ver1.3.5.txt** → điểm từ (pos - neg)\n",
        "- **NegDict.txt** → từ phủ định (không, chẳng, chưa, ...)\n",
        "- **SacThaiDict.txt** → từ nhấn mạnh / mức độ (rất, quá, cực_kỳ, ...)\n",
        "\n",
        "> Lưu ý: `underthesea.word_tokenize(format=\"text\")` sẽ nối từ ghép bằng dấu `_`\n",
        "> (ví dụ: `tốt nhất` → `tốt_nhất`). Vì vậy notebook chuẩn hoá lexicon để match kiểu token này. citeturn0search4\n"
      ],
      "id": "eAGrsSTI3woA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwNal47o3woF"
      },
      "source": [
        "## 0) Chuẩn bị file\n",
        "\n",
        "Đặt các file này **cùng thư mục** với notebook:\n",
        "\n",
        "- `VietSentiWordnet_Ver1.3.5.txt`\n",
        "- `NegDict.txt`\n",
        "- `SacThaiDict.txt`\n",
        "\n",
        "Nếu bạn để chỗ khác thì sửa lại biến `LEXICON_PATH / NEG_PATH / INTENS_PATH` ở cell bên dưới.\n"
      ],
      "id": "uwNal47o3woF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_u_q1TM3woH"
      },
      "source": [
        "# (Tuỳ chọn) Cài thư viện nếu máy bạn chưa có\n",
        "!pip -q install underthesea pandas\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "id": "e_u_q1TM3woH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Ga1AJ13woK"
      },
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Set, Tuple, Optional\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from underthesea import word_tokenize\n",
        "except Exception:\n",
        "    word_tokenize = None\n",
        "\n",
        "# ==== ĐƯỜNG DẪN 3 FILE (sửa ở đây nếu cần) ====\n",
        "BASE_DIR = Path(\".\")  # thư mục notebook\n",
        "LEXICON_PATH = BASE_DIR / \"VietSentiWordnet_Ver1.3.5.txt\"\n",
        "NEG_PATH = BASE_DIR / \"NegDict.txt\"\n",
        "INTENS_PATH = BASE_DIR / \"SacThaiDict.txt\"\n",
        "\n",
        "# ==== normalize / tokenize ====\n",
        "URL_RE = re.compile(r\"http\\S+|www\\.\\S+\", flags=re.IGNORECASE)\n",
        "NON_ALPHA_RE = re.compile(r\"[^0-9a-zA-ZÀ-ỹ_ ]+\")\n",
        "\n",
        "def nfc(s: str) -> str:\n",
        "    return unicodedata.normalize(\"NFC\", s)\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = nfc(text).lower()\n",
        "    text = URL_RE.sub(\" \", text)\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = NON_ALPHA_RE.sub(\" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def tokenize_vi(text: str) -> List[str]:\n",
        "    text = normalize_text(text)\n",
        "    if word_tokenize is None:\n",
        "        return text.split()\n",
        "    # underthesea format=\"text\" sẽ nối cụm từ bằng \"_\"\n",
        "    return nfc(word_tokenize(text, format=\"text\")).split()\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "id": "O6Ga1AJ13woK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2y9LyQa3woM"
      },
      "source": [
        "def load_word_list(path: Path) -> Set[str]:\n",
        "    words: Set[str] = set()\n",
        "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        for line in f:\n",
        "            w = nfc(line.strip()).lower()\n",
        "            if not w or w.startswith(\"#\"):\n",
        "                continue\n",
        "            # chuẩn hoá \"tốt nhất\" -> \"tốt_nhất\" để match tokenization\n",
        "            w = w.replace(\" \", \"_\")\n",
        "            words.add(w)\n",
        "    return words\n",
        "\n",
        "def load_intensifiers(path: Path) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    SacThaiDict.txt thường là: word<tab>weight\n",
        "    Nhưng cũng có thể là: word weight  (space)\n",
        "    \"\"\"\n",
        "    intens: Dict[str, float] = {}\n",
        "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        for raw in f:\n",
        "            line = nfc(raw.strip())\n",
        "            if not line or line.startswith(\"#\"):\n",
        "                continue\n",
        "            parts = re.split(r\"\\s+\", line)\n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            word = parts[0].lower().replace(\" \", \"_\")\n",
        "            try:\n",
        "                weight = float(parts[1].replace(\",\", \".\"))\n",
        "            except ValueError:\n",
        "                continue\n",
        "            intens[word] = weight\n",
        "    return intens\n",
        "\n",
        "def _parse_synset_terms(synset_terms: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    SynsetTerms ví dụ: \"tốt_hơn#3 tốt nhất#2\"\n",
        "    -> cần tách theo mẫu kết thúc \"#<digits>\"\n",
        "    \"\"\"\n",
        "    synset_terms = nfc(synset_terms.strip())\n",
        "    return [m.group(1).strip() for m in re.finditer(r\"(.+?#\\d+)(?=\\s+|$)\", synset_terms)]\n",
        "\n",
        "def load_vnsenti_lexicon(path: Path) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Format mỗi dòng (tab-separated):\n",
        "      POS \\t ID \\t PosScore \\t NegScore \\t SynsetTerms \\t Gloss\n",
        "    Trả về: lemma -> avg(PosScore - NegScore)\n",
        "    \"\"\"\n",
        "    lex_sum: Dict[str, float] = defaultdict(float)\n",
        "    lex_cnt: Dict[str, int] = defaultdict(int)\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        for raw in f:\n",
        "            line = nfc(raw.strip())\n",
        "            if not line or line.startswith(\"#\"):\n",
        "                continue\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            if parts[0].lower() == \"pos\":  # header (nếu có)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                pos_score = float(parts[2].replace(\",\", \".\"))\n",
        "                neg_score = float(parts[3].replace(\",\", \".\"))\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            score = pos_score - neg_score\n",
        "            for term in _parse_synset_terms(parts[4]):\n",
        "                lemma = term.rsplit(\"#\", 1)[0].strip().lower()\n",
        "                if not lemma:\n",
        "                    continue\n",
        "                lemma = nfc(lemma.replace(\" \", \"_\"))\n",
        "                lex_sum[lemma] += score\n",
        "                lex_cnt[lemma] += 1\n",
        "\n",
        "    return {w: lex_sum[w] / lex_cnt[w] for w in lex_sum.keys()}\n"
      ],
      "outputs": [],
      "execution_count": 18,
      "id": "H2y9LyQa3woM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEmDRhLV3woN"
      },
      "source": [
        "stopwords = load_word_list(\"vietnamese-stopwords-dash.txt\")\n",
        "\n",
        "def preprocess(text: str) -> List[str]:\n",
        "    tokens = tokenize_vi(text)\n",
        "    out = []\n",
        "    for t in tokens:\n",
        "        # giữ negation + intensifier để rule hoạt động\n",
        "        if t in neg_words or t in intens:\n",
        "            out.append(t)\n",
        "            continue\n",
        "        # lọc stopword\n",
        "        if t in stopwords:\n",
        "            continue\n",
        "        out.append(t)\n",
        "    return out\n",
        "\n",
        "# def preprocess(text: str) -> List[str]:\n",
        "#     tokens = tokenize_vi(text)\n",
        "#     return [nfc(t).lower().strip() for t in tokens if t.strip()]\n",
        "\n",
        "def sentiment_score(\n",
        "    tokens: List[str],\n",
        "    lexicon: Dict[str, float],\n",
        "    neg_words: Set[str],\n",
        "    intens: Dict[str, float],\n",
        "    neg_window: int = 3,\n",
        ") -> float:\n",
        "    total = 0.0\n",
        "    for i, tok in enumerate(tokens):\n",
        "        if tok in neg_words:\n",
        "            continue\n",
        "\n",
        "        s = lexicon.get(tok)\n",
        "        if s is None:\n",
        "            continue\n",
        "\n",
        "        # intensifier ngay trước\n",
        "        if i > 0 and tokens[i - 1] in intens:\n",
        "            s *= intens[tokens[i - 1]]\n",
        "\n",
        "        # có phủ định trong cửa sổ phía trước\n",
        "        start = max(0, i - neg_window)\n",
        "        if any(t in neg_words for t in tokens[start:i]):\n",
        "            s *= -1\n",
        "\n",
        "        total += s\n",
        "\n",
        "    return float(total)\n",
        "\n",
        "def score_to_label(score: float, pos_th: float = 0.05, neg_th: float = -0.05) -> str:\n",
        "    if score > pos_th:\n",
        "        return \"positive\"\n",
        "    if score < neg_th:\n",
        "        return \"negative\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def predict_sentiment(\n",
        "    text: str,\n",
        "    lexicon: Dict[str, float],\n",
        "    neg_words: Set[str],\n",
        "    intens: Dict[str, float],\n",
        "    pos_th: float = 0.05,\n",
        "    neg_th: float = -0.05,\n",
        "    neg_window: int = 3,\n",
        ") -> Tuple[str, float]:\n",
        "    tokens = preprocess(text)\n",
        "    sc = sentiment_score(tokens, lexicon, neg_words, intens, neg_window=neg_window)\n",
        "    return score_to_label(sc, pos_th, neg_th), sc\n"
      ],
      "outputs": [],
      "execution_count": 19,
      "id": "kEmDRhLV3woN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5e4J1de3woN",
        "outputId": "04c7a975-192b-4763-e839-c8bb5dc54092"
      },
      "source": [
        "# ==== Load 3 resources ====\n",
        "assert LEXICON_PATH.exists(), f\"Không thấy file: {LEXICON_PATH}\"\n",
        "assert NEG_PATH.exists(), f\"Không thấy file: {NEG_PATH}\"\n",
        "assert INTENS_PATH.exists(), f\"Không thấy file: {INTENS_PATH}\"\n",
        "\n",
        "lexicon = load_vnsenti_lexicon(LEXICON_PATH)\n",
        "neg_words = load_word_list(NEG_PATH)\n",
        "intens = load_intensifiers(INTENS_PATH)\n",
        "\n",
        "print(\"Lexicon size:\", len(lexicon))\n",
        "print(\"Neg words:\", len(neg_words))\n",
        "print(\"Intensifiers:\", len(intens))\n",
        "\n",
        "# ==== Demo nhanh ====\n",
        "examples = [\n",
        "    \"Điện thoại này rất tốt, pin trâu và màn hình đẹp.\",\n",
        "    \"Sản phẩm quá tệ, dùng được vài hôm là hỏng.\",\n",
        "    \"Tạm ổn, không có gì đặc biệt.\",\n",
        "    \"Chất lượng không tốt như mong đợi.\",\n",
        "    \"Mình không hề thất vọng, thậm chí rất hài lòng.\",\n",
        "    \"Hoàn toàn không đáng tiền, quá thất vọng.\",\n",
        "    \"Không tệ như mình nghĩ, dùng cũng ổn.\",\n",
        "]\n",
        "\n",
        "for s in examples:\n",
        "    lab, sc = predict_sentiment(s, lexicon, neg_words, intens)\n",
        "    print(f\"- {s} -> {lab:8s} | score={sc:.3f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexicon size: 1191\n",
            "Neg words: 11\n",
            "Intensifiers: 16\n",
            "- Điện thoại này rất tốt, pin trâu và màn hình đẹp. -> positive | score=0.625\n",
            "- Sản phẩm quá tệ, dùng được vài hôm là hỏng. -> negative | score=-1.375\n",
            "- Tạm ổn, không có gì đặc biệt. -> neutral  | score=0.000\n",
            "- Chất lượng không tốt như mong đợi. -> positive | score=0.500\n",
            "- Mình không hề thất vọng, thậm chí rất hài lòng. -> positive | score=1.875\n",
            "- Hoàn toàn không đáng tiền, quá thất vọng. -> positive | score=0.875\n",
            "- Không tệ như mình nghĩ, dùng cũng ổn. -> positive | score=0.625\n"
          ]
        }
      ],
      "execution_count": 20,
      "id": "-5e4J1de3woN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Gyc2oScj3woO",
        "outputId": "dbab2721-bb2b-4aa0-8cd7-b04ad98fee6c"
      },
      "source": [
        "from typing import Optional, List\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def predict_on_csv(\n",
        "    csv_path: str,\n",
        "    text_col: str = \"text\",\n",
        "    out_path: Optional[str] = None,\n",
        "    pos_th: float = 0.05,\n",
        "    neg_th: float = -0.05,\n",
        "    neg_window: int = 3,\n",
        ") -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if text_col not in df.columns:\n",
        "        raise ValueError(f\"Missing text column: {text_col}. Available: {list(df.columns)}\")\n",
        "\n",
        "    preds: List[str] = []\n",
        "    scores: List[float] = []\n",
        "\n",
        "    for txt in df[text_col].astype(str).tolist():\n",
        "        lab, sc = predict_sentiment(\n",
        "            txt, lexicon, neg_words, intens,\n",
        "            pos_th=pos_th, neg_th=neg_th, neg_window=neg_window\n",
        "        )\n",
        "        preds.append(lab)\n",
        "        scores.append(sc)\n",
        "\n",
        "    df[\"pred_label\"] = preds\n",
        "    df[\"pred_score\"] = scores\n",
        "\n",
        "    # Nếu có label thì in metric (macro-F1 + accuracy)\n",
        "    if \"label\" in df.columns:\n",
        "        y_true = df[\"label\"].astype(str)\n",
        "        y_pred = df[\"pred_label\"].astype(str)\n",
        "        print(\"Accuracy :\", f\"{accuracy_score(y_true, y_pred):.4f}\")\n",
        "        print(\"Macro-F1 :\", f\"{f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
        "\n",
        "    if out_path:\n",
        "        df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "        print(\"Saved:\", out_path)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Ví dụ (chạy đúng file data_graded.csv):\n",
        "df_pred = predict_on_csv(\"data_graded.csv\", text_col=\"text\", out_path=\"data_graded.pred.csv\")\n",
        "df_pred.head()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.5745\n",
            "Macro-F1 : 0.5761\n",
            "Saved: data_graded.pred.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id difficulty                                               text     label  \\\n",
              "0   1       easy  Đáng tiền, pin trâu, màn hình đẹp. Mình sẽ cân...  positive   \n",
              "1   2       easy  Giao hàng nhanh, đóng gói cẩn thận. Nếu cải th...  positive   \n",
              "2   3       easy                    Sản phẩm rất tốt, dùng ổn định.  positive   \n",
              "3   4       easy                        Âm thanh hay, thiết kế đẹp.  positive   \n",
              "4   5       easy  Đáng tiền, pin trâu, màn hình đẹp. Không biết ...  positive   \n",
              "\n",
              "  pred_label  pred_score  \n",
              "0   positive       0.625  \n",
              "1   positive       0.500  \n",
              "2   positive       0.750  \n",
              "3   positive       0.625  \n",
              "4   positive       0.625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-615566b2-80ff-4ed0-80a9-de3bf9ae44b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>pred_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>easy</td>\n",
              "      <td>Đáng tiền, pin trâu, màn hình đẹp. Mình sẽ cân...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>easy</td>\n",
              "      <td>Giao hàng nhanh, đóng gói cẩn thận. Nếu cải th...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>easy</td>\n",
              "      <td>Sản phẩm rất tốt, dùng ổn định.</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>easy</td>\n",
              "      <td>Âm thanh hay, thiết kế đẹp.</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>easy</td>\n",
              "      <td>Đáng tiền, pin trâu, màn hình đẹp. Không biết ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-615566b2-80ff-4ed0-80a9-de3bf9ae44b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-615566b2-80ff-4ed0-80a9-de3bf9ae44b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-615566b2-80ff-4ed0-80a9-de3bf9ae44b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47357745-8557-48c5-89f5-2769e660942c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47357745-8557-48c5-89f5-2769e660942c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47357745-8557-48c5-89f5-2769e660942c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pred",
              "summary": "{\n  \"name\": \"df_pred\",\n  \"rows\": 510,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 147,\n        \"min\": 1,\n        \"max\": 510,\n        \"num_unique_values\": 510,\n        \"samples\": [\n          481,\n          450,\n          476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"easy\",\n          \"medium\",\n          \"hard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 240,\n        \"samples\": [\n          \"Ch\\u1ea5t l\\u01b0\\u1ee3ng tuy\\u1ec7t v\\u1eddi, m\\u00ecnh r\\u1ea5t h\\u00e0i l\\u00f2ng. Tr\\u1ea3i nghi\\u1ec7m kh\\u00e1 \\u1ed5n.\",\n          \"Ch\\u1ea5t l\\u01b0\\u1ee3ng tuy\\u1ec7t v\\u1eddi, m\\u00ecnh r\\u1ea5t h\\u00e0i l\\u00f2ng.\",\n          \"Thi\\u1ebft k\\u1ebf \\u0111\\u1eb9p v\\u00e0 pin \\u1ed5n, nh\\u00ecn chung \\u0111\\u00e1ng mua. Tr\\u1ea3i nghi\\u1ec7m kh\\u00e1 \\u1ed5n.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7288498380263504,\n        \"min\": -2.0,\n        \"max\": 2.375,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.625,\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "execution_count": 21,
      "id": "Gyc2oScj3woO"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}